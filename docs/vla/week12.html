<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-vla/vla-week12" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Week 12: Implementing a VLA with Isaac ROS | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://hi01tech.github.io/humanoid-robotics-book/docs/vla/week12"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Week 12: Implementing a VLA with Isaac ROS | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="This week, we will get hands-on with implementing a VLA. We will use the NVIDIA Isaac ROS stack to accelerate our perception pipeline and connect it to a VLA model to generate robot actions."><meta data-rh="true" property="og:description" content="This week, we will get hands-on with implementing a VLA. We will use the NVIDIA Isaac ROS stack to accelerate our perception pipeline and connect it to a VLA model to generate robot actions."><link data-rh="true" rel="icon" href="/humanoid-robotics-book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://hi01tech.github.io/humanoid-robotics-book/docs/vla/week12"><link data-rh="true" rel="alternate" href="https://hi01tech.github.io/humanoid-robotics-book/docs/vla/week12" hreflang="en"><link data-rh="true" rel="alternate" href="https://hi01tech.github.io/humanoid-robotics-book/docs/vla/week12" hreflang="x-default"><link rel="stylesheet" href="/humanoid-robotics-book/assets/css/styles.c37c557d.css">
<link rel="preload" href="/humanoid-robotics-book/assets/js/runtime~main.018f0728.js" as="script">
<link rel="preload" href="/humanoid-robotics-book/assets/js/main.886c07b3.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/humanoid-robotics-book/"><div class="navbar__logo"><img src="/humanoid-robotics-book/img/logo.png" alt="Logo" class="themedImage_ToTc themedImage--light_HNdA" height="50" width="50"><img src="/humanoid-robotics-book/img/logo.png" alt="Logo" class="themedImage_ToTc themedImage--dark_i4oU" height="50" width="50"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/humanoid-robotics-book/docs/introduction-setup">Textbook</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/humanoid-robotics-book/search">Search</a><a class="navbar__item navbar__link" href="/humanoid-robotics-book/chatbot">Chatbot</a><div class="toggle_vylO colorModeToggle_x44X"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbar__item languageToggle_FqXF"><select class="languageSelect_ti5h"><option selected="" value="en">English</option><option value="ur">اردو</option></select></div> <div class="searchBox_H2mL"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/humanoid-robotics-book/docs/introduction-setup">Introduction &amp; Setup</a><button aria-label="Toggle the collapsible sidebar category &#x27;Introduction &amp; Setup&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/humanoid-robotics-book/docs/ros2-module">Module 1: ROS 2</a><button aria-label="Toggle the collapsible sidebar category &#x27;Module 1: ROS 2&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/humanoid-robotics-book/docs/digital-twin-module">Module 2: Digital Twin</a><button aria-label="Toggle the collapsible sidebar category &#x27;Module 2: Digital Twin&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/humanoid-robotics-book/docs/isaac-module">Module 3: NVIDIA Isaac</a><button aria-label="Toggle the collapsible sidebar category &#x27;Module 3: NVIDIA Isaac&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/humanoid-robotics-book/docs/vla-module">Module 4: VLA</a><button aria-label="Toggle the collapsible sidebar category &#x27;Module 4: VLA&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/humanoid-robotics-book/docs/vla/week11">Week 11: VLA Intro</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/humanoid-robotics-book/docs/vla/week12">Week 12: VLA with Isaac ROS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/humanoid-robotics-book/docs/vla/week13">Week 13: The Future</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/humanoid-robotics-book/docs/assessments">Assessments</a><button aria-label="Toggle the collapsible sidebar category &#x27;Assessments&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/humanoid-robotics-book/docs/reference">Reference</a><button aria-label="Toggle the collapsible sidebar category &#x27;Reference&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/humanoid-robotics-book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/humanoid-robotics-book/docs/vla-module"><span itemprop="name">Module 4: VLA</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Week 12: VLA with Isaac ROS</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Week 12: Implementing a VLA with Isaac ROS</h1><p>This week, we will get hands-on with implementing a VLA. We will use the NVIDIA Isaac ROS stack to accelerate our perception pipeline and connect it to a VLA model to generate robot actions.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="topics-covered">Topics Covered<a href="#topics-covered" class="hash-link" aria-label="Direct link to Topics Covered" title="Direct link to Topics Covered">​</a></h2><ul><li><strong>Isaac ROS Gems:</strong> An overview of the available perception packages.</li><li><strong>Building a Perception Pipeline:</strong> From camera feed to object detections.</li><li><strong>Connecting a VLA to ROS 2:</strong> How to send perceptions to the model and receive actions.</li><li><strong>&quot;Hello, Robot&quot; - VLA Style:</strong> A simple end-to-end example.</li></ul><p>This week, we will get hands-on with implementing a VLA. We will use the NVIDIA Isaac ROS stack to accelerate our perception pipeline and connect it to a VLA model to generate robot actions.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="isaac-ros-gems">Isaac ROS Gems<a href="#isaac-ros-gems" class="hash-link" aria-label="Direct link to Isaac ROS Gems" title="Direct link to Isaac ROS Gems">​</a></h2><p>NVIDIA Isaac ROS is a collection of hardware-accelerated packages (called &quot;Gems&quot;) that provide high-performance building blocks for ROS 2 applications on NVIDIA platforms. These Gems leverage the power of NVIDIA GPUs and other specialized hardware to significantly speed up common robotics tasks, especially in perception and AI.</p><p>Key categories of Isaac ROS Gems include:</p><ul><li><strong>Perception:</strong> Gems for camera processing, depth estimation, stereo vision, object detection, and segmentation. These are crucial for providing the visual input to VLA models.</li><li><strong>Navigation:</strong> Gems for SLAM, localization, and path planning.</li><li><strong>Manipulation:</strong> Gems for robotic arm control, grasping, and inverse kinematics.</li><li><strong>Core:</strong> Utilities and drivers for NVIDIA hardware.</li></ul><p>By using Isaac ROS Gems, developers can achieve real-time performance for complex perception tasks that would be computationally intensive on a CPU-only system. This acceleration is vital for humanoid robots that need to react quickly and intelligently to their environment.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="building-a-perception-pipeline">Building a Perception Pipeline<a href="#building-a-perception-pipeline" class="hash-link" aria-label="Direct link to Building a Perception Pipeline" title="Direct link to Building a Perception Pipeline">​</a></h2><p>A <strong>perception pipeline</strong> is a sequence of processing steps that transforms raw sensor data into meaningful information about the environment. For a VLA, the perception pipeline typically starts with camera feeds and ends with representations that the VLA can understand.</p><p>Here&#x27;s a conceptual outline of a perception pipeline using Isaac ROS:</p><ol><li><strong>Camera Driver:</strong> An Isaac ROS camera driver (e.g., <code>isaac_ros_argus_camera</code> for NVIDIA Jetson devices) publishes raw camera images (<code>sensor_msgs/Image</code>) to a ROS 2 topic. In simulation, this data comes directly from Isaac Sim&#x27;s simulated cameras.</li><li><strong>Image Preprocessing:</strong><ul><li><strong>Rectification/Debayering:</strong> Correcting lens distortions and converting raw sensor data into a standard RGB image format. Isaac ROS provides optimized Gems for these tasks (e.g., <code>isaac_ros_image_proc</code>).</li><li><strong>Resizing/Cropping:</strong> Adjusting image dimensions to match the input requirements of the perception model.</li></ul></li><li><strong>Object Detection/Segmentation:</strong><ul><li><strong>Isaac ROS DNN Inference:</strong> Gems like <code>isaac_ros_detectnet</code> or <code>isaac_ros_yolov8</code> can take preprocessed images and run deep neural networks for tasks like object detection (outputting bounding boxes and labels) or instance segmentation (outputting pixel-level masks for objects).</li><li><strong>Data Conversion:</strong> The output of these DNNs is typically converted into standard ROS 2 messages (e.g., <code>vision_msgs/Detection2DArray</code> or <code>sensor_msgs/Image</code> for masks).</li></ul></li><li><strong>Tracking (Optional):</strong> If the robot needs to follow objects over time, an object tracking Gem can be used to associate detections across consecutive frames.</li><li><strong>Output:</strong> The final output of the perception pipeline might be a stream of detected objects, their locations, and potentially their semantic labels, which are then fed into the VLA model.</li></ol><p>This modular approach, leveraging hardware-accelerated Gems, allows for flexible and high-performance perception systems critical for real-time robotic operation.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="connecting-a-vla-to-ros-2">Connecting a VLA to ROS 2<a href="#connecting-a-vla-to-ros-2" class="hash-link" aria-label="Direct link to Connecting a VLA to ROS 2" title="Direct link to Connecting a VLA to ROS 2">​</a></h2><p>Integrating a VLA model, especially a large one, into a ROS 2 system involves careful consideration of data flow and communication. The goal is to efficiently pass perception data to the VLA and receive action commands back to control the robot.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-flow">Data Flow<a href="#data-flow" class="hash-link" aria-label="Direct link to Data Flow" title="Direct link to Data Flow">​</a></h3><ol><li><p><strong>Perception Output to VLA Input:</strong> The output of your Isaac ROS perception pipeline (e.g., detected objects, semantic segmentation masks, processed point clouds) needs to be formatted and sent to the VLA model. This often involves:</p><ul><li><p><strong>Serialization:</strong> Converting ROS 2 messages into a format consumable by the VLA model (e.g., NumPy arrays, tensors, JSON).</p></li><li><p><strong>Inference Server:</strong> For large VLA models, an dedicated inference server (e.g., NVIDIA Triton Inference Server) might host the model. ROS 2 nodes would send requests to this server.</p></li><li><p><strong>Direct Integration:</strong> For smaller or local models, the VLA inference might run directly within a ROS 2 node.</p></li></ul></li><li><p><strong>Language Input to VLA:</strong> Natural language commands from a user (e.g., via a speech-to-text system or a GUI) are also fed into the VLA model. This input is typically a simple string.</p></li><li><p><strong>VLA Output to Robot Control:</strong> The VLA model&#x27;s output, which represents the desired robot actions (e.g., joint commands, end-effector poses, high-level task instructions), needs to be translated back into ROS 2 commands for the robot&#x27;s controllers.</p><ul><li><strong>Action Translation Node:</strong> A dedicated ROS 2 node can interpret the VLA&#x27;s output and generate appropriate <code>ros2_control</code> commands or navigation goals.</li></ul></li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="communication-patterns">Communication Patterns<a href="#communication-patterns" class="hash-link" aria-label="Direct link to Communication Patterns" title="Direct link to Communication Patterns">​</a></h3><ul><li><p><strong>Topics:</strong> For continuous streams of perception data or feedback.</p></li><li><p><strong>Services:</strong> For explicit requests to the VLA (e.g., &quot;analyze this scene&quot; or &quot;generate a plan for this instruction&quot;) where a synchronous response is desired.</p></li><li><p><strong>Actions:</strong> For long-running VLA-generated tasks (e.g., &quot;pick up all blue objects&quot;) where feedback and preemption are important.</p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="hello-robot---vla-style">&quot;Hello, Robot&quot; - VLA Style<a href="#hello-robot---vla-style" class="hash-link" aria-label="Direct link to &quot;Hello, Robot&quot; - VLA Style" title="Direct link to &quot;Hello, Robot&quot; - VLA Style">​</a></h2><p>Let&#x27;s imagine a simple end-to-end example of a VLA in action for a humanoid robot.</p><p><strong>Scenario:</strong> A user tells the robot: &quot;Go to the red table and bring me the cup.&quot;</p><p><strong>VLA Pipeline:</strong></p><ol><li><p><strong>User Input:</strong> The user&#x27;s speech is converted to text: &quot;Go to the red table and bring me the cup.&quot;</p></li><li><p><strong>Language Embedding:</strong> The VLA&#x27;s language encoder processes this text.</p></li><li><p><strong>Visual Perception (Isaac ROS):</strong></p><ul><li><p>The robot&#x27;s cameras feed into an Isaac ROS perception pipeline (e.g., object detection for &quot;table&quot; and &quot;cup&quot;, color segmentation for &quot;red&quot;).</p></li><li><p>The pipeline identifies a &quot;red table&quot; and a &quot;cup&quot; on it, determining their 3D poses in the robot&#x27;s environment.</p></li></ul></li><li><p><strong>VLA Decision Making:</strong> The VLA model, combining the language instruction and the visual perceptions, synthesizes a plan:</p><ul><li><p><strong>Task 1:</strong> Navigate to the red table.</p></li><li><p><strong>Task 2:</strong> Pick up the cup.</p></li><li><p><strong>Task 3:</strong> Bring the cup to the user.</p></li></ul></li><li><p><strong>Action Generation &amp; Execution:</strong></p><ul><li><p><strong>Navigate:</strong> The VLA translates &quot;Navigate to the red table&quot; into a series of navigation goals, which are sent to the robot&#x27;s navigation stack.</p></li><li><p><strong>Manipulate:</strong> Once at the table, the VLA translates &quot;Pick up the cup&quot; into a sequence of arm movements and grasping commands (potentially using inverse kinematics and motion planning for collision avoidance). These are sent to <code>ros2_control</code>.</p></li><li><p><strong>Return:</strong> Finally, &quot;Bring me the cup&quot; leads to another navigation goal and possibly a presentation pose for the cup.</p></li></ul></li></ol><p>This &quot;Hello, Robot&quot; moment highlights the power of VLAs to bridge the gap between human intent and complex robot behavior, creating a more intuitive and capable robotic assistant.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/humanoid-robotics-book/docs/vla/week11"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Week 11: VLA Intro</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/humanoid-robotics-book/docs/vla/week13"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Week 13: The Future</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#topics-covered" class="table-of-contents__link toc-highlight">Topics Covered</a></li><li><a href="#isaac-ros-gems" class="table-of-contents__link toc-highlight">Isaac ROS Gems</a></li><li><a href="#building-a-perception-pipeline" class="table-of-contents__link toc-highlight">Building a Perception Pipeline</a></li><li><a href="#connecting-a-vla-to-ros-2" class="table-of-contents__link toc-highlight">Connecting a VLA to ROS 2</a><ul><li><a href="#data-flow" class="table-of-contents__link toc-highlight">Data Flow</a></li><li><a href="#communication-patterns" class="table-of-contents__link toc-highlight">Communication Patterns</a></li></ul></li><li><a href="#hello-robot---vla-style" class="table-of-contents__link toc-highlight">&quot;Hello, Robot&quot; - VLA Style</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Textbook. Built with Docusaurus.</div></div></div></footer></div>
<script src="/humanoid-robotics-book/assets/js/runtime~main.018f0728.js"></script>
<script src="/humanoid-robotics-book/assets/js/main.886c07b3.js"></script>
</body>
</html>
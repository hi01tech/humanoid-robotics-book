"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[230],{464(e,t,a){a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>g,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var n=a(8168),r=(a(6540),a(5680));const i={id:"capstone-project-guide",title:"Capstone Project Guide",sidebar_label:"Capstone Project Guide",estimated_time:10,week:13,module:"Capstone",prerequisites:["vla-week13"],learning_objectives:["Design and implement a complete humanoid robotics system based on the 5-step architecture","Integrate ROS 2, Isaac Sim, and Isaac ROS components","Apply VLA concepts to a practical robotics problem","Demonstrate robust system operation in simulation"]},o="Capstone Project Guide",l={unversionedId:"assessments/capstone-project-guide",id:"assessments/capstone-project-guide",title:"Capstone Project Guide",description:'The Capstone Project is the culmination of your learning in "Physical AI & Humanoid Robotics." You will design, implement, and evaluate a robotic system that addresses a real-world problem, integrating the concepts and technologies covered throughout the course.',source:"@site/docs/assessments/capstone-project-guide.md",sourceDirName:"assessments",slug:"/assessments/capstone-project-guide",permalink:"/docs/assessments/capstone-project-guide",draft:!1,tags:[],version:"current",frontMatter:{id:"capstone-project-guide",title:"Capstone Project Guide",sidebar_label:"Capstone Project Guide",estimated_time:10,week:13,module:"Capstone",prerequisites:["vla-week13"],learning_objectives:["Design and implement a complete humanoid robotics system based on the 5-step architecture","Integrate ROS 2, Isaac Sim, and Isaac ROS components","Apply VLA concepts to a practical robotics problem","Demonstrate robust system operation in simulation"]},sidebar:"tutorialSidebar",previous:{title:"Isaac Assessment",permalink:"/docs/assessments/isaac-sim-assessment"},next:{title:"Reference",permalink:"/docs/reference"}},s={},c=[{value:"Project Goal",id:"project-goal",level:2},{value:"Mandatory 5-Step Architecture",id:"mandatory-5-step-architecture",level:2},{value:"1. Voice (Natural Language Interface)",id:"1-voice-natural-language-interface",level:3},{value:"2. Plan (Task and Motion Planning)",id:"2-plan-task-and-motion-planning",level:3},{value:"3. Navigate (Locomotion and Path Execution)",id:"3-navigate-locomotion-and-path-execution",level:3},{value:"4. Perceive (Environmental Understanding)",id:"4-perceive-environmental-understanding",level:3},{value:"5. Manipulate (Object Interaction)",id:"5-manipulate-object-interaction",level:3},{value:"Evaluation Rubric",id:"evaluation-rubric",level:2}],p={toc:c};function g({components:e,...t}){return(0,r.yg)("wrapper",(0,n.A)({},p,t,{components:e,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"capstone-project-guide"},"Capstone Project Guide"),(0,r.yg)("p",null,'The Capstone Project is the culmination of your learning in "Physical AI & Humanoid Robotics." You will design, implement, and evaluate a robotic system that addresses a real-world problem, integrating the concepts and technologies covered throughout the course.'),(0,r.yg)("p",null,"Your project must adhere to the mandatory ",(0,r.yg)("strong",{parentName:"p"},"5-step architecture"),": ",(0,r.yg)("strong",{parentName:"p"},"Voice \u2192 Plan \u2192 Navigate \u2192 Perceive \u2192 Manipulate"),"."),(0,r.yg)("h2",{id:"project-goal"},"Project Goal"),(0,r.yg)("p",null,"Design a humanoid robotics system that can autonomously perform a pick-and-place task in a dynamic, unstructured environment within NVIDIA Isaac Sim. The robot should respond to high-level natural language commands."),(0,r.yg)("h2",{id:"mandatory-5-step-architecture"},"Mandatory 5-Step Architecture"),(0,r.yg)("h3",{id:"1-voice-natural-language-interface"},"1. Voice (Natural Language Interface)"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Objective"),": Convert natural language commands into structured, actionable instructions for the robot."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Requirements"),":",(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},'Implement a simple command-line interface or mock text input for natural language commands (e.g., "Pick up the red cube and place it on the green mat").'),(0,r.yg)("li",{parentName:"ul"},"Parse the command to extract key entities (objects, locations, actions) and convert them into a machine-readable format."))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Example Technologies"),": Rule-based parsing, simple intent recognition, or a mock API call to a VLM.")),(0,r.yg)("h3",{id:"2-plan-task-and-motion-planning"},"2. Plan (Task and Motion Planning)"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Objective"),": Generate a sequence of high-level actions and corresponding motion plans to execute the task."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Requirements"),":",(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},'Based on the structured instructions from the "Voice" step, break down the task into sub-tasks (e.g., "navigate to object", "perceive object", "grasp object", "navigate to target", "place object").'),(0,r.yg)("li",{parentName:"ul"},"For each sub-task, use appropriate planning algorithms (e.g., A","*"," for navigation, sampling-based planners for manipulation)."))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Example Technologies"),": Behavior trees, state machines, MoveIt! (for path planning), simple kinematic solvers.")),(0,r.yg)("h3",{id:"3-navigate-locomotion-and-path-execution"},"3. Navigate (Locomotion and Path Execution)"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Objective"),": Move the robot through the environment to reach desired locations."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Requirements"),":",(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},"Implement a navigation stack (even a simplified one) that takes target waypoints and generates velocity commands."),(0,r.yg)("li",{parentName:"ul"},"Utilize sensory input (e.g., simulated LiDAR or depth camera) to avoid obstacles."),(0,r.yg)("li",{parentName:"ul"},"Control the robot's base using ",(0,r.yg)("inlineCode",{parentName:"li"},"ros2_control")," in Isaac Sim."))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Example Technologies"),": ROS 2 Navigation stack (Nav2), simple potential field methods, ",(0,r.yg)("inlineCode",{parentName:"li"},"ros2_control")," differential drive controller.")),(0,r.yg)("h3",{id:"4-perceive-environmental-understanding"},"4. Perceive (Environmental Understanding)"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Objective"),": Sense the environment to identify objects, estimate their poses, and understand scene layout."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Requirements"),":",(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},"Use simulated camera data from Isaac Sim."),(0,r.yg)("li",{parentName:"ul"},"Implement object detection using Isaac ROS or a similar deep learning framework to identify target objects."),(0,r.yg)("li",{parentName:"ul"},"Estimate the 3D pose (position and orientation) of identified objects."))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Example Technologies"),": Isaac ROS (object detection, perception modules), OpenCV, PCL (Point Cloud Library).")),(0,r.yg)("h3",{id:"5-manipulate-object-interaction"},"5. Manipulate (Object Interaction)"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Objective"),": Interact with objects (e.g., grasp, lift, place) using the robot's end-effector."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Requirements"),":",(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},"Implement inverse kinematics to position the end-effector."),(0,r.yg)("li",{parentName:"ul"},"Control the robot's arm and gripper using ",(0,r.yg)("inlineCode",{parentName:"li"},"ros2_control")," in Isaac Sim."),(0,r.yg)("li",{parentName:"ul"},"Execute grasping and releasing actions."))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Example Technologies"),": ",(0,r.yg)("inlineCode",{parentName:"li"},"ros2_control")," (joint trajectory controller), simple inverse kinematics solver, pre-defined grasp poses.")),(0,r.yg)("h2",{id:"evaluation-rubric"},"Evaluation Rubric"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Criteria"),(0,r.yg)("th",{parentName:"tr",align:null},"Needs Improvement"),(0,r.yg)("th",{parentName:"tr",align:null},"Meets Expectations"),(0,r.yg)("th",{parentName:"tr",align:null},"Exceeds Expectations"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Voice Interface")),(0,r.yg)("td",{parentName:"tr",align:null},"Command parsing fails for basic inputs; instructions not actionable."),(0,r.yg)("td",{parentName:"tr",align:null},"Simple command parsing works; generates structured instructions for robot."),(0,r.yg)("td",{parentName:"tr",align:null},"Robust NLP interface; handles varied commands, asks clarifying questions.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Planning")),(0,r.yg)("td",{parentName:"tr",align:null},"Task breakdown is illogical; motion plans fail to execute."),(0,r.yg)("td",{parentName:"tr",align:null},"Generates reasonable task sequence; basic motion planning achieved."),(0,r.yg)("td",{parentName:"tr",align:null},"Optimal task sequencing; intelligent motion planning with collision avoidance.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Navigation")),(0,r.yg)("td",{parentName:"tr",align:null},"Robot collides; fails to reach targets; control is unstable."),(0,r.yg)("td",{parentName:"tr",align:null},"Robot navigates to target waypoints; basic obstacle avoidance."),(0,r.yg)("td",{parentName:"tr",align:null},"Efficient, collision-free navigation; adapts to dynamic obstacles.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Perception")),(0,r.yg)("td",{parentName:"tr",align:null},"Objects not detected; pose estimation is inaccurate/missing."),(0,r.yg)("td",{parentName:"tr",align:null},"Detects target objects; provides reasonable 3D pose estimates."),(0,r.yg)("td",{parentName:"tr",align:null},"High accuracy object detection/pose estimation; handles occlusions/noise.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Manipulation")),(0,r.yg)("td",{parentName:"tr",align:null},"Robot fails to grasp/place; motions are jerky/unsafe."),(0,r.yg)("td",{parentName:"tr",align:null},"Successfully grasps and places objects; basic arm/gripper control."),(0,r.yg)("td",{parentName:"tr",align:null},"Smooth, precise, and robust grasping/placement; handles object variability.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Integration")),(0,r.yg)("td",{parentName:"tr",align:null},"Modules are disconnected; system requires manual intervention."),(0,r.yg)("td",{parentName:"tr",align:null},"All 5 modules are integrated; system can complete basic task autonomously."),(0,r.yg)("td",{parentName:"tr",align:null},"Seamless integration; system robustly completes complex tasks; handles exceptions.")))))}g.isMDXComponent=!0},5680(e,t,a){a.d(t,{xA:()=>p,yg:()=>u});var n=a(6540);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter(function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable})),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach(function(t){r(e,t,a[t])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach(function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))})}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),c=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},g={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef(function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=c(a),u=r,d=m["".concat(s,".").concat(u)]||m[u]||g[u]||i;return a?n.createElement(d,o(o({ref:t},p),{},{components:a})):n.createElement(d,o({ref:t},p))});function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var c=2;c<i;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"}}]);